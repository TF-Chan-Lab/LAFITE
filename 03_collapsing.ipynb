{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: collapsing.html\n",
    "title: read_collapsing\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp read_collapsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from dataclasses import dataclass, field\n",
    "from time import strftime\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from LAFITE.utils import loc_distance, Vividict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "@ dataclass\n",
    "class RawAttributeCollection:\n",
    "    name: str\n",
    "    start: int\n",
    "    end: int\n",
    "    fsm: bool = False\n",
    "    multi_exon: bool = True\n",
    "    correct_site: list = field(default_factory=list)\n",
    "    merge_gap: list = field(default_factory=list)\n",
    "    polyaed: bool = False\n",
    "    lowCredit_junction: dict = field(default_factory=dict)\n",
    "    splicing_tag: list = field(default_factory=list)\n",
    "    rss_dis: int = None\n",
    "    res_dis: int = None\n",
    "    collapsed_ID: str = None\n",
    "    reference_id: str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "class ReadCorrectionColappse:\n",
    "    def __init__(self, chrom, strand, chrand_processed_read, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans, chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, sj_correction_window, mis_intron_length, polya_dict, corExcept_dis=0):\n",
    "        self.chrom = chrom\n",
    "        self.strand = strand\n",
    "        self.chrand_processed_read = chrand_processed_read\n",
    "        self.chrand_ref_exon = chrand_ref_exon\n",
    "        self.chrand_ref_junction = chrand_ref_junction\n",
    "        self.chrand_ref_single_exon_trans = chrand_ref_single_exon_trans\n",
    "        self.chrand_ref_mutple_exon_trans = chrand_ref_mutple_exon_trans\n",
    "        self.chrand_left_sj_set = chrand_left_sj_set\n",
    "        self.chrand_right_sj_set = chrand_right_sj_set\n",
    "        self.chrand_junction_dict = chrand_junction_dict\n",
    "        self.sj_correction_window = sj_correction_window\n",
    "        self.mis_intron_length = mis_intron_length\n",
    "        self.polya_dict = polya_dict\n",
    "        self.corExcept_dis = corExcept_dis\n",
    "\n",
    "    def single_exon_read_collapse(self, read, single_exon_read):\n",
    "        \"\"\"\n",
    "        remove the single-exon reads overlaped with exon from reference multi-exon transcript and collapse\"\"\"\n",
    "        start, end = read\n",
    "        if self.chrand_ref_exon:\n",
    "            overlapped_ref_exon = tuple(self.chrand_ref_exon.find(read))\n",
    "            if overlapped_ref_exon:\n",
    "                for exon in overlapped_ref_exon:\n",
    "                    if exon[0] <= start+self.sj_correction_window and exon[1] >= end-self.sj_correction_window:\n",
    "                        read = []\n",
    "                        break\n",
    "        if read:\n",
    "            counter = Counter(range(start, end+1))\n",
    "            for i in counter:\n",
    "                if i in single_exon_read:\n",
    "                    single_exon_read[i] += counter[i]\n",
    "                else:\n",
    "                    single_exon_read[i] = counter[i]\n",
    "\n",
    "        return single_exon_read\n",
    "\n",
    "    def RTS_refrence_distance(self, start, end, read_splicing):\n",
    "        \"\"\"calculate the distance between read start/end site to the reference transcript start/end site for FSM reads\n",
    "\n",
    "        Args:\n",
    "                strand (str): strand information\n",
    "                start (int): genomic start position regardless of strand\n",
    "                end (int): genomic end position regardless of strand\n",
    "                read_splicing (tuple): corrected read splicing\n",
    "                chrand_ref_mutple_exon_trans (dict): reference multi-exon transcript\n",
    "        \"\"\"\n",
    "        if self.strand == '+':\n",
    "            rss_dis = abs(\n",
    "                self.chrand_ref_mutple_exon_trans[read_splicing][0]-start)\n",
    "            res_dis = abs(\n",
    "                self.chrand_ref_mutple_exon_trans[read_splicing][1]-end)\n",
    "        else:\n",
    "            rss_dis = abs(\n",
    "                self.chrand_ref_mutple_exon_trans[read_splicing][0]-end)\n",
    "            res_dis = abs(\n",
    "                self.chrand_ref_mutple_exon_trans[read_splicing][1]-start)\n",
    "\n",
    "        return rss_dis, res_dis\n",
    "\n",
    "    def multi_exon_read_correction(self, read_id, full_block):\n",
    "        \"\"\"\n",
    "        splicing junction correction and collaspsing for multi-exon read\"\"\"\n",
    "\n",
    "        raw_splicing = tuple(full_block[1:-1])\n",
    "        raw_read_attribute = RawAttributeCollection(\n",
    "            read_id, full_block[0], full_block[-1])\n",
    "        corrected_read_splicing = []\n",
    "\n",
    "        # polya event checking\n",
    "        try:\n",
    "            if self.polya_dict[read_id]:\n",
    "                raw_read_attribute.polyaed = True\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if raw_splicing in self.chrand_ref_mutple_exon_trans:  # raw read_splicing matching with the reference\n",
    "            raw_read_attribute.fsm = True\n",
    "            raw_read_attribute.splicing_tag = 'FSM'\n",
    "            corrected_read_splicing = raw_splicing\n",
    "            raw_read_attribute.rss_dis, raw_read_attribute.res_dis = self.RTS_refrence_distance(\n",
    "                raw_read_attribute.start, raw_read_attribute.end, corrected_read_splicing)\n",
    "\n",
    "        else:  # splicing site correction\n",
    "            itered_raw_splicing = iter(raw_splicing)\n",
    "            for idx, (left_sj, right_sj) in enumerate(zip(itered_raw_splicing, itered_raw_splicing)):\n",
    "\n",
    "                # check splicing coverage and motif in raw data\n",
    "                sj_pos = full_block.index(left_sj)\n",
    "                tmp_sj = (self.chrom, self.strand, left_sj, right_sj)\n",
    "                junction_coverage = self.chrand_junction_dict[tmp_sj][0]\n",
    "                junction_motif = self.chrand_junction_dict[tmp_sj][2]\n",
    "\n",
    "                if left_sj in self.chrand_left_sj_set and right_sj in self.chrand_right_sj_set:\n",
    "                    if (left_sj, right_sj) in self.chrand_ref_junction:\n",
    "                        raw_read_attribute.splicing_tag.append('M')\n",
    "                    else:\n",
    "                        raw_read_attribute.splicing_tag.append('KC')\n",
    "\n",
    "                elif self.chrand_left_sj_set:\n",
    "                    left_dis, left_ref_sj = loc_distance(\n",
    "                        self.chrand_left_sj_set, left_sj)\n",
    "                    right_dis, right_ref_sj = loc_distance(\n",
    "                        self.chrand_right_sj_set, right_sj)\n",
    "\n",
    "                    # do not correct the splicing site once the edit distance > sj_correction_window\n",
    "                    if left_dis > self.sj_correction_window:\n",
    "                        left_ref_sj = left_sj\n",
    "                    if right_dis > self.sj_correction_window:\n",
    "                        right_ref_sj = right_sj\n",
    "\n",
    "                    # correction exception, splicing junction with edit distance less than the given value for both sides\n",
    "                    if self.corExcept_dis and left_dis <= self.corExcept_dis and right_dis <= self.corExcept_dis and junction_coverage > 1 and junction_motif == 'canonical':\n",
    "                        raw_read_attribute.splicing_tag.append('EXC')\n",
    "\n",
    "                    # splicing site correction\n",
    "                    elif left_dis <= self.sj_correction_window or right_dis <= self.sj_correction_window:\n",
    "                        if [left_sj, right_sj] == [left_ref_sj, right_ref_sj]:\n",
    "                            pass\n",
    "                        elif full_block[sj_pos-1] < left_ref_sj < right_ref_sj < full_block[sj_pos+2]:\n",
    "                            raw_read_attribute.correct_site.append(\n",
    "                                [left_sj, right_sj])\n",
    "                            left_sj, right_sj = left_ref_sj, right_ref_sj\n",
    "\n",
    "                        if left_sj in self.chrand_left_sj_set and right_sj in self.chrand_right_sj_set:\n",
    "                            if (left_sj, right_sj) in self.chrand_ref_junction:\n",
    "                                raw_read_attribute.splicing_tag.append('CM')\n",
    "                            else:\n",
    "                                raw_read_attribute.splicing_tag.append('CKC')\n",
    "\n",
    "                # checking unintended small intron overlap with reference exons\n",
    "                if len(raw_read_attribute.splicing_tag) == idx and right_sj - left_sj <= self.mis_intron_length:\n",
    "                    if self.chrand_ref_exon:\n",
    "                        overlapped_ref_exon = tuple(\n",
    "                            self.chrand_ref_exon.find((left_sj, right_sj)))\n",
    "                    else:\n",
    "                        overlapped_ref_exon = ()\n",
    "                    # compare the unintended intron with the ref_exon from multi-exon transcripts\n",
    "                    if idx == 0 and overlapped_ref_exon:\n",
    "                        for exon in overlapped_ref_exon:\n",
    "                            if (len(full_block) == 4 and exon[1] >= right_sj and exon[0] <= left_sj):\n",
    "                                raw_read_attribute.merge_gap.append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                raw_read_attribute.multi_exon = False\n",
    "                                break\n",
    "                            elif (exon[1] == full_block[sj_pos+2] and exon[0] <= left_sj):\n",
    "                                raw_read_attribute.merge_gap.append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                break\n",
    "\n",
    "                    elif idx == int(len(raw_splicing)/2 - 1) and overlapped_ref_exon:\n",
    "                        for exon in overlapped_ref_exon:\n",
    "                            if exon[1] >= right_sj and exon[0] == full_block[sj_pos-1]:\n",
    "                                raw_read_attribute.merge_gap.append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                break\n",
    "\n",
    "                    elif 0 < idx < int(len(raw_splicing)/2 - 1) and overlapped_ref_exon:\n",
    "                        for exon in overlapped_ref_exon:\n",
    "                            if exon[1] == full_block[sj_pos+2] and exon[0] == full_block[sj_pos-1]:\n",
    "                                raw_read_attribute.merge_gap.append(\n",
    "                                    [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                break\n",
    "\n",
    "                    # compare the unintended intron with the exon from single-exon transcripts\n",
    "                    elif not overlapped_ref_exon and len(full_block) == 4:\n",
    "                        if self.chrand_ref_single_exon_trans:\n",
    "                            overlapped_ref_exon = tuple(\n",
    "                                self.chrand_ref_single_exon_trans.find((left_sj, right_sj)))\n",
    "\n",
    "                        if overlapped_ref_exon:\n",
    "                            for exon in overlapped_ref_exon:\n",
    "                                if exon[1] >= right_sj and exon[0] <= left_sj:\n",
    "                                    raw_read_attribute.merge_gap.append(\n",
    "                                        [full_block[sj_pos], full_block[sj_pos+1]])\n",
    "                                    raw_read_attribute.multi_exon = False\n",
    "                                    break\n",
    "\n",
    "                corrected_read_splicing.extend([left_sj, right_sj])\n",
    "\n",
    "                if [full_block[sj_pos], full_block[sj_pos+1]] in raw_read_attribute.merge_gap:\n",
    "                    raw_read_attribute.splicing_tag.append('UI')\n",
    "                    del corrected_read_splicing[-2:]\n",
    "\n",
    "                elif len(raw_read_attribute.splicing_tag) == idx:\n",
    "                    raw_read_attribute.splicing_tag.append('NC')\n",
    "                    if junction_coverage == 1:\n",
    "                        raw_read_attribute.lowCredit_junction[idx +\n",
    "                                                              1] = junction_motif\n",
    "\n",
    "            corrected_read_splicing = tuple(corrected_read_splicing)\n",
    "            if corrected_read_splicing in self.chrand_ref_mutple_exon_trans:\n",
    "                raw_read_attribute.fsm = True\n",
    "                raw_read_attribute.rss_dis, raw_read_attribute.res_dis = self.RTS_refrence_distance(\n",
    "                    raw_read_attribute.start, raw_read_attribute.end, corrected_read_splicing)\n",
    "                raw_read_attribute.reference_id = self.chrand_ref_mutple_exon_trans[\n",
    "                    corrected_read_splicing][2]\n",
    "\n",
    "        return corrected_read_splicing, raw_read_attribute\n",
    "\n",
    "    def multi_exon_read_collapse(self, corrected_read_splicing, raw_read_attribute, rss_dis_lst, res_dis_lst, multi_exon_read, collapsed_idx):\n",
    "        \"\"\"collapsing multi-exon read\n",
    "        \"\"\"\n",
    "        prefix = 'POS' if self.strand == '+' else 'NEG'\n",
    "        if raw_read_attribute.lowCredit_junction:\n",
    "            pass\n",
    "        elif corrected_read_splicing:\n",
    "            if corrected_read_splicing not in multi_exon_read:\n",
    "                collapsed_idx += 1\n",
    "                raw_read_attribute.collapsed_ID = f'{self.chrom}_{prefix}.{collapsed_idx}'\n",
    "                multi_exon_read[corrected_read_splicing] = [[raw_read_attribute.start], [raw_read_attribute.end], [\n",
    "                    raw_read_attribute.polyaed], 1, raw_read_attribute.fsm, raw_read_attribute.collapsed_ID, [raw_read_attribute.reference_id]]\n",
    "            else:\n",
    "                multi_exon_read[corrected_read_splicing][0].insert(\n",
    "                    0, raw_read_attribute.start)\n",
    "                multi_exon_read[corrected_read_splicing][1].insert(\n",
    "                    0, raw_read_attribute.end)\n",
    "                multi_exon_read[corrected_read_splicing][2].insert(\n",
    "                    0, raw_read_attribute.polyaed)\n",
    "                multi_exon_read[corrected_read_splicing][3] += 1\n",
    "\n",
    "                raw_read_attribute.collapsed_ID = multi_exon_read[corrected_read_splicing][5]\n",
    "                multi_exon_read[corrected_read_splicing][6].insert(\n",
    "                    0, raw_read_attribute.reference_id)\n",
    "\n",
    "        if raw_read_attribute.rss_dis:\n",
    "            rss_dis_lst.append(raw_read_attribute.rss_dis)\n",
    "            res_dis_lst.append(raw_read_attribute.res_dis)\n",
    "        # print(len(multi_exon_read[corrected_read_splicing]))\n",
    "        return multi_exon_read, rss_dis_lst, res_dis_lst, collapsed_idx, raw_read_attribute\n",
    "\n",
    "    def coco_operation(self, collapsed_idx=0):\n",
    "        \"\"\"main function for correcting splicing junction and collpasing reads\n",
    "        \"\"\"\n",
    "        corrected_read = defaultdict(dict)\n",
    "        correction_log = defaultdict(dict)\n",
    "        single_exon_read = defaultdict(dict)\n",
    "        multi_exon_read = defaultdict(dict)\n",
    "        rss_dis_lst = []\n",
    "        res_dis_lst = []\n",
    "\n",
    "        for read_id, full_block in tqdm(self.chrand_processed_read.items(), desc=f'{strftime(\"%Y-%m-%d %H:%M:%S\")}: Collapsing raw reads from {self.chrom} {self.strand}'):\n",
    "\n",
    "            # single-exon read collapsing\n",
    "            if len(full_block) == 2:\n",
    "                single_exon_read = self.single_exon_read_collapse(\n",
    "                    full_block, single_exon_read)\n",
    "                corrected_read[read_id] = full_block\n",
    "            # multi-exon read correction and collapsing\n",
    "            else:\n",
    "                corrected_read_splicing, raw_read_attribute = self.multi_exon_read_correction(\n",
    "                    read_id, full_block)\n",
    "                multi_exon_read, rss_dis_lst, res_dis_lst, collapsed_idx, raw_read_attribute = self.multi_exon_read_collapse(\n",
    "                    corrected_read_splicing, raw_read_attribute, rss_dis_lst, res_dis_lst, multi_exon_read, collapsed_idx)\n",
    "\n",
    "                if corrected_read_splicing:\n",
    "                    corrected_read[read_id] = [\n",
    "                        raw_read_attribute.start, *list(corrected_read_splicing), raw_read_attribute.end]\n",
    "                else:\n",
    "                    corrected_read[read_id] = [\n",
    "                        raw_read_attribute.start, raw_read_attribute.end]\n",
    "                correction_log[read_id] = raw_read_attribute\n",
    "\n",
    "        return self.chrom, self.strand, single_exon_read, multi_exon_read, corrected_read, correction_log, rss_dis_lst, res_dis_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "class CoCoWrapper:\n",
    "    def __init__(self, thread, processed_read, ref_exon, ref_junction, ref_single_exon_trans, ref_mutple_exon_trans, left_sj_set, right_sj_set, junction_dict, sj_correction_window, polya_dict, mis_intron_length, tmp_dir, corExcept_dis=0):\n",
    "        self.thread = thread\n",
    "        self.processed_read = processed_read\n",
    "        self.ref_exon = ref_exon\n",
    "        self.ref_junction = ref_junction\n",
    "        self.ref_single_exon_trans = ref_single_exon_trans\n",
    "        self.ref_mutple_exon_trans = ref_mutple_exon_trans\n",
    "        self.left_sj_set = left_sj_set\n",
    "        self.right_sj_set = right_sj_set\n",
    "        self.junction_dict = junction_dict\n",
    "        self.sj_correction_window = sj_correction_window\n",
    "        self.polya_dict = polya_dict\n",
    "        self.mis_intron_length = mis_intron_length\n",
    "        self.tmp_dir = tmp_dir\n",
    "        self.corExcept_dis = corExcept_dis\n",
    "\n",
    "    def job_compute(self):\n",
    "\n",
    "        job = []\n",
    "        for branch in self.processed_read:\n",
    "            chrom, strand = branch\n",
    "            chrand_processed_read = self.processed_read[branch]\n",
    "            chrand_ref_exon = self.ref_exon[branch]\n",
    "            chrand_ref_junction = self.ref_junction[branch]\n",
    "            chrand_ref_single_exon_trans = self.ref_single_exon_trans[branch]\n",
    "            chrand_ref_mutple_exon_trans = self.ref_mutple_exon_trans[branch]\n",
    "            chrand_left_sj_set = self.left_sj_set[branch]\n",
    "            chrand_right_sj_set = self.right_sj_set[branch]\n",
    "            chrand_junction_dict = self.junction_dict[branch]\n",
    "            job.append(ReadCorrectionColappse(chrom, strand, chrand_processed_read, chrand_ref_exon, chrand_ref_junction, chrand_ref_single_exon_trans,\n",
    "                                              chrand_ref_mutple_exon_trans, chrand_left_sj_set, chrand_right_sj_set, chrand_junction_dict, self.sj_correction_window, self.mis_intron_length, self.polya_dict, self.corExcept_dis))\n",
    "        p = Pool(processes=self.thread)\n",
    "        result = [p.apply_async(i.coco_operation, args=()) for i in job]\n",
    "        p.close()\n",
    "        p.join()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def result_collection(self):\n",
    "        collected_single_exon_read = Vividict()\n",
    "        collected_multi_exon_read = Vividict()\n",
    "        collected_rss = []\n",
    "        collected_res = []\n",
    "        path_to_log = f'{self.tmp_dir}/read_correction.log'\n",
    "        path_to_corrected_bed = f'{self.tmp_dir}/Corrected_reads.bed'\n",
    "\n",
    "        result = self.job_compute()\n",
    "        with open(path_to_log, 'w') as flog, open(path_to_corrected_bed, 'w') as fbed:\n",
    "            for res in result:\n",
    "                chrom, strand, single_exon_read, multi_exon_read, corrected_read, correction_log, rss_dis_lst, res_dis_lst = res.get()\n",
    "\n",
    "                collected_single_exon_read[(chrom, strand)] = single_exon_read\n",
    "                collected_multi_exon_read[(chrom, strand)] = multi_exon_read\n",
    "                collected_rss.extend(rss_dis_lst)\n",
    "                collected_res.extend(res_dis_lst)\n",
    "                for read_id, raw_read_attribute in correction_log.items():\n",
    "                    raw_read_attribute.name = raw_read_attribute.name.split('_', 1)[\n",
    "                        1]\n",
    "                    attributes = '\\t'.join('{}: {}'.format(\n",
    "                        key, value) for key, value in raw_read_attribute.__dict__.items())\n",
    "                    flog.write(f'{attributes}\\n')\n",
    "\n",
    "                for read_id, full_block in corrected_read.items():\n",
    "                    read_name = read_id.split('_', 1)[1]\n",
    "                    bed_block = splicing_to_bed_block(\n",
    "                        chrom, strand, read_name, full_block)\n",
    "                    fbed.write(f'{bed_block}\\n')\n",
    "        return collected_single_exon_read, collected_multi_exon_read, collected_rss, collected_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "def splicing_to_bed_block(chrom, strand, name, full_block):\n",
    "    start, end = full_block[0], full_block[-1]\n",
    "    full_block = iter(full_block)\n",
    "    block_sizes = []\n",
    "    block_starts = []\n",
    "    for left_end, right_end in zip(full_block, full_block):\n",
    "        block_starts.append(left_end - start)\n",
    "        block_sizes.append(right_end - left_end + 1)\n",
    "    block_count = len(block_sizes)\n",
    "    block_sizes = ','.join([str(i) for i in block_sizes])\n",
    "    block_starts = ','.join([str(i) for i in block_starts])\n",
    "    bed_block = [chrom, start-1, end, name, '-', strand, start -\n",
    "                 1, end, '255,0,0', block_count, block_sizes, block_starts]\n",
    "    bed_block = '\\t'.join([str(i) for i in bed_block])\n",
    "\n",
    "    return bed_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
